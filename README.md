# Ultralytics YOLO11 - Object Detection & Instance Segmentation

A comprehensive YOLO11-based system for object detection and instance segmentation tasks using the Ultralytics framework.

## ğŸ“‹ Project Overview

This project provides a complete solution for:
- **Object Detection**: Real-time detection of objects in images and videos
- **Instance Segmentation**: Pixel-level segmentation of detected objects
- **Model Training**: Train custom YOLO11 models on your own datasets
- **Inference**: Run predictions on images, videos, or webcam feeds

## ğŸ“ Project Structure

```
ultralytics_yolo/
â”œâ”€â”€ train.py           # Model training script
â”œâ”€â”€ predict.py         # Inference and prediction script
â”œâ”€â”€ export.py          # Model export functionality
â”œâ”€â”€ setup.bat          # Windows environment setup script
â”œâ”€â”€ requirements.txt   # Python dependencies
â”œâ”€â”€ yolo11n.pt         # Pre-trained YOLO11-nano model
â””â”€â”€ .gitignore         # Git ignore rules
```

## ğŸš€ Quick Start

### Prerequisites
- Python 3.8 or higher
- Windows OS (or modify setup.bat for other systems)

### Installation (Windows)

1. **Automatic Setup (Recommended)**
   ```bash
   setup.bat
   ```
   This will:
   - Create a Python virtual environment
   - Activate the environment
   - Install all required dependencies

2. **Manual Setup**
   ```bash
   # Create virtual environment
   py -3 -m venv venv
   
   # Activate virtual environment
   venv\Scripts\activate
   
   # Install dependencies
   pip install -r requirements.txt
   ```

## ğŸ“¦ Dependencies

- **ultralytics** (â‰¥8.0.0) - YOLO detection framework
- **opencv-python** (â‰¥4.8.0) - Image processing
- **torch** (â‰¥2.0.0) - Deep learning framework (auto-installed)
- **torchvision** (â‰¥0.15.0) - Computer vision utilities
- **numpy** (â‰¥1.23.0) - Numerical computing
- **pillow** (â‰¥10.0.0) - Image library
- **tqdm** (â‰¥4.66.0) - Progress bars

## ğŸ¯ Usage

### Training a Model

```bash
# Activate virtual environment first
venv\Scripts\activate

# Run training script
python train.py
```

**Features:**
- Choose between Object Detection or Instance Segmentation
- Select from multiple pre-trained models (nano, small, medium, large, xlarge)
- Customize training parameters (epochs, batch size, image size)
- Specify your dataset path (COCO format)
- Automatic model saving to `runs/` directory

**Supported Models:**
- yolo11n.pt (Nano - fastest, lowest accuracy)
- yolo11s.pt (Small - balanced)
- yolo11m.pt (Medium - higher accuracy)
- yolo11l.pt (Large - slower, high accuracy)
- yolo11x.pt (XLarge - slowest, best accuracy)

### Running Inference

```bash
# Activate virtual environment first
venv\Scripts\activate

# Run prediction script
python predict.py
```

**Input Options:**
1. **Webcam**: Real-time detection from your camera
2. **Image Folder**: Batch process images from a directory

**Detection Modes:**
1. Object Detection
2. Instance Segmentation

### Exporting Models

```bash
python export.py
```

Export trained models to various formats for deployment.

## ğŸ“Š Output

- Detection results are saved to the `runs/` directory (auto-created)
- Includes:
  - `detect/` - Detection results
  - `segment/` - Segmentation results
  - `train/` - Training logs and weights
  - Each run has subdirectories with timestamps

## ğŸ› ï¸ Model Selection Guide

| Model | Speed | Accuracy | Memory | Use Case |
|-------|-------|----------|--------|----------|
| yolo11n | âš¡âš¡âš¡ | â­ | ğŸ’¾ | Real-time on edge devices |
| yolo11s | âš¡âš¡ | â­â­ | ğŸ’¾ğŸ’¾ | Balanced performance |
| yolo11m | âš¡ | â­â­â­ | ğŸ’¾ğŸ’¾ğŸ’¾ | High accuracy applications |
| yolo11l | - | â­â­â­â­ | ğŸ’¾ğŸ’¾ğŸ’¾ğŸ’¾ | Maximum accuracy |
| yolo11x | - | â­â­â­â­â­ | ğŸ’¾ğŸ’¾ğŸ’¾ğŸ’¾ğŸ’¾ | Best accuracy (slow) |

## ğŸ“ Dataset Format

The project expects datasets in COCO format:
```
dataset/
â”œâ”€â”€ images/
â”‚   â”œâ”€â”€ train/
â”‚   â”œâ”€â”€ val/
â”‚   â””â”€â”€ test/
â””â”€â”€ labels/
    â”œâ”€â”€ train/
    â”œâ”€â”€ val/
    â””â”€â”€ test/
```

## âš™ï¸ Configuration

### Training Parameters (Interactive)
- Model selection (nano to xlarge)
- Number of epochs
- Batch size
- Image resolution
- Dataset path
- Device selection (GPU/CPU)

### Inference Parameters (Interactive)
- Mode selection (detection or segmentation)
- Source selection (webcam or folder)
- Confidence threshold
- IOU threshold

## ğŸ“– Resource Links

- [Ultralytics Documentation](https://docs.ultralytics.com/)
- [YOLO GitHub Repository](https://github.com/ultralytics/ultralytics)
- [PyTorch Documentation](https://pytorch.org/docs/)
- [COCO Dataset Format](https://cocodataset.org/)

## ğŸ“Œ Important Notes

- The `runs/` directory contains training outputs and predictions (not tracked in Git)
- Model files (`*.pt`) are not tracked in Git (they can be large)
- Use GPU when available for significantly faster training and inference
- For server environments without display, use `opencv-python-headless` instead

## ğŸ¤ Troubleshooting

### GPU Not Detected
```bash
# Verify PyTorch GPU support
python -c "import torch; print(torch.cuda.is_available())"
```

### Out of Memory Errors
- Reduce batch size
- Use a smaller model (nano or small)
- Reduce image resolution

### OpenCV Display Issues (Linux/Server)
- Use `opencv-python-headless` from requirements.txt
- Or save results to disk instead of displaying

## ğŸ“„ License

This project uses Ultralytics YOLO11, which is available under the AGPL-3.0 license.

## ğŸ‘¤ Author Notes

Built with the Ultralytics YOLO framework for efficient object detection and segmentation tasks.

---

**Last Updated**: January 2026
